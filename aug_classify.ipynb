{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTjd419DWbvX"
   },
   "outputs": [],
   "source": [
    "# first we uninstall tf version 1.4 \n",
    "\n",
    "!pip uninstall tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RZSG6LZbT8k"
   },
   "outputs": [],
   "source": [
    "#importing...\n",
    "# installing tf 2.0 and augmentor\n",
    "\n",
    "!pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "!pip install Augmentor\n",
    "import Augmentor\n",
    "from shutil import copy\n",
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "#mport tensorflow_datasets as tfds\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHoWIAILay1I"
   },
   "outputs": [],
   "source": [
    "#copy all training images to a new folder named new_data\n",
    "\n",
    "\n",
    "shutil.rmtree(\"New_data\", ignore_errors = True)\n",
    "os.mkdir(\"New_data\")\n",
    "dest = \"New_data\"\n",
    "src = ['category 1', 'category 2', 'category 3', 'category 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQyFTZIoa3Kd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGSzKvVwbF5F"
   },
   "outputs": [],
   "source": [
    "# copy images to one folder\n",
    "#do note that due ro for loop it will print 100% four times\n",
    "for i in src:\n",
    "    f = os.path.join('/content/drive/My Drive/Image_2.zip (Unzipped Files)/Image_2/Input/Dataset/train/',i)\n",
    "    for img in tqdm(os.listdir(f)): \n",
    "            print(img)\n",
    "            path = os.path.join(f,img)\n",
    "            print(path)\n",
    "            copy(path, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufh1WR9AbK71"
   },
   "outputs": [],
   "source": [
    "# path to new data directory\n",
    "data_dir = \"New_data\"\n",
    "# image size that we want\n",
    "img_size = 150\n",
    "\n",
    "#path to augmented images\n",
    "output = \"New_data/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiqziOd6cVgw"
   },
   "outputs": [],
   "source": [
    "#producing augmented images\n",
    "\n",
    "p = Augmentor.Pipeline(data_dir)\n",
    "p.rotate270(probability=0.2)\n",
    "p.flip_top_bottom(0.2)\n",
    "p.flip_left_right(probability=0.2)\n",
    "p.random_distortion(probability=0.1, grid_width=4, grid_height=4, magnitude=8)\n",
    "#p.zoom_random(0.1, percentage_area=0.8)\n",
    "p.sample(10000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbTCZOKmcaLk"
   },
   "outputs": [],
   "source": [
    "#producing labels\n",
    "\n",
    "\n",
    "def label_img(img):\n",
    "    label = img.split('_')[3]\n",
    "    if label == 'category 1': return 0\n",
    "    elif label == 'category 2': return 1\n",
    "    elif label == 'category 3': return 2\n",
    "    elif label == 'category 4': return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJDctA6tcfjP"
   },
   "outputs": [],
   "source": [
    "#creating numpyfile from images in output folder\n",
    "#this function can create both training and test data\n",
    "def tdata(flag):\n",
    "    output = \"New_data/output\"\n",
    "    if flag == 'test':\n",
    "        output = \"/content/drive/My Drive/Image_2.zip (Unzipped Files)/Image_2/Input/Dataset/test\"\n",
    "    data = []\n",
    "    ids = {}\n",
    "    values = []\n",
    "    i = 0\n",
    "    for img in tqdm(os.listdir(output)):\n",
    "          \n",
    "        path = os.path.join(output,img)\n",
    "        if flag == 'train':\n",
    "            \n",
    "            label = label_img(img)\n",
    "            \n",
    "        \n",
    "        \n",
    "        try:\n",
    "          \n",
    "            \n",
    "            im = cv2.resize(cv2.imread(path),(img_size, img_size))\n",
    "            grayImage = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "            normalizedImg = np.zeros((150, 150, 1))\n",
    "            normalizedImg = cv2.normalize(grayImage,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
    "            if flag == 'train':\n",
    "                data.append([np.array(normalizedImg),  np.array(label)])\n",
    "                \n",
    "            #for test data we will include image name , so that we can keep track of the prediction for images\n",
    "            \n",
    "            else:\n",
    "                values.append(img) \n",
    "                ids[i] = values[i]\n",
    "                data.append([np.array(normalizedImg)])\n",
    "                i +=1 \n",
    "\n",
    "        except Exception as e:\n",
    "                    print('skipping...')\n",
    "                    print(e)\n",
    "        \n",
    "                   \n",
    "   \n",
    "    if flag == 'train':\n",
    "            # we shuffle in case of training but not in test data\n",
    "            shuffle(data)\n",
    "            shutil.rmtree('train_data.npy', ignore_errors = True)\n",
    "            np.save('train_data.npy', data)\n",
    "    else :\n",
    "        shutil.rmtree('test_data.npy', ignore_errors = True)\n",
    "        np.save('test_data.npy', data)\n",
    "        \n",
    "        return ids  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCG96z7adP-V"
   },
   "outputs": [],
   "source": [
    "tdata('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BX9t4eIdWaq"
   },
   "outputs": [],
   "source": [
    "#opening numpyfile\n",
    "\n",
    "data = np.load('train_data.npy',allow_pickle=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYR17HyPdaof"
   },
   "outputs": [],
   "source": [
    "#spliting into train and eval set\n",
    "np.random.shuffle(data)\n",
    "training, evaluate = data[:8000,:], data[8000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRtRxCcXdp3-"
   },
   "outputs": [],
   "source": [
    "print(training.shape)\n",
    "print(training[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNwwuIDgd6pq"
   },
   "outputs": [],
   "source": [
    "#ploting first image\n",
    "\n",
    "for i in range(5):\n",
    "        print(training[i,1])\n",
    "        plt.imshow(training[i,0], cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHLRmkocd9U9"
   },
   "outputs": [],
   "source": [
    "\n",
    "#spliting features and labels\n",
    "\n",
    "FEATURES = []\n",
    "LABELS = []\n",
    "\n",
    "for feature, label in  training:\n",
    "    FEATURES.append(feature)\n",
    "    LABELS.append(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ux3DCWvKeBzU"
   },
   "outputs": [],
   "source": [
    "X_TRAIN = np.array(FEATURES).reshape(-1, img_size, img_size, 1)\n",
    "Y_TRAIN = np.array(LABELS)\n",
    "print(X_TRAIN.shape,Y_TRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TuIvSxZteFNJ"
   },
   "outputs": [],
   "source": [
    "X_EVAL = []\n",
    "Y_EVAL = []\n",
    "\n",
    "for feature, label in  evaluate:\n",
    "    X_EVAL.append(feature)\n",
    "    Y_EVAL.append(label)\n",
    "    \n",
    "X_EVAL = np.array(X_EVAL).reshape(-1, img_size, img_size, 1)\n",
    "Y_EVAL = np.array(Y_EVAL)\n",
    "\n",
    "buffer = 60000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# making dataset\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_TRAIN,Y_TRAIN)).shuffle(buffer).batch(BATCH_SIZE)\n",
    "eval_dataset = tf.data.Dataset.from_tensor_slices((X_EVAL,Y_EVAL)).shuffle(buffer).batch(BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGpbbDo2eJQa"
   },
   "outputs": [],
   "source": [
    "# CNN model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001), input_shape=[150, 150,1]))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(layers.Dense(4, activation='softmax'))   \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRuVvcj4eO1T"
   },
   "outputs": [],
   "source": [
    "\n",
    "#checkpoints\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,save_weights_only=True,verbose=1)\n",
    "\n",
    "#tensorboard \n",
    "callbacks = tf.keras.callbacks.TensorBoard('./logs_keras')\n",
    "\n",
    "#earlystopping\n",
    "\n",
    "#callback2 = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWuLw0FZea-Q"
   },
   "outputs": [],
   "source": [
    "\n",
    "#compile and running training\n",
    "\n",
    "model.compile(optimizer=tf.compat.v2.optimizers.Adadelta(0.01),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset, epochs=200, verbose=1, validation_data=(eval_dataset), callbacks=[callbacks, cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SaInF6Veib1"
   },
   "outputs": [],
   "source": [
    "#train from latest check point\n",
    "tf.train.latest_checkpoint(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HugkvJh7eloH"
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir ./logs_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-Hd48yCtclp"
   },
   "outputs": [],
   "source": [
    "#create test data in numpy file\n",
    "\n",
    "idds = tdata('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FmZTp94P_oPr"
   },
   "outputs": [],
   "source": [
    "idds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H85OPiWxerZN"
   },
   "outputs": [],
   "source": [
    "# load test data and seperate test images and their name\n",
    "\n",
    "data = np.load('test_data.npy',allow_pickle=True)\n",
    "        \n",
    "d = data.squeeze().reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "\n",
    "#d = data[0].squeeze().reshape(-1, 150, 150, 1)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7r3Zgk5zeuwx"
   },
   "outputs": [],
   "source": [
    "#getting prediction\n",
    "\n",
    "prid = model.predict(d)\n",
    "print(prid)\n",
    "for i in prid:\n",
    "      print(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vau0w0qqvyua"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "dictn = {0:'category 1', 1:'category 2', 2 :'category 3', 3:'category 4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwjthRo_u4t3"
   },
   "outputs": [],
   "source": [
    "#writting result to a csv file using pandas\n",
    "\n",
    "\n",
    "prid_data = pd.DataFrame({'image_Id':idds,'predicted_labels':dictn[np.argmax(prid)]})\n",
    "#age_Id'] = data['image_Id'].astype('int')\n",
    "#prid_data['predicted_labels'] = data['predicted_labels'].astype('str')\n",
    "prid_data.to_csv('submission.csv')\n",
    "print(prid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zeywZChoncF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
